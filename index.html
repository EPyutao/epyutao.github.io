<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.0" />






<meta name="description" content="念念不忘 必有回响">
<meta property="og:type" content="website">
<meta property="og:title" content="EPyutao">
<meta property="og:url" content="http://EPyutao.com/index.html">
<meta property="og:site_name" content="EPyutao">
<meta property="og:description" content="念念不忘 必有回响">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EPyutao">
<meta name="twitter:description" content="念念不忘 必有回响">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"hide","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://EPyutao.com/"/>





  <title> EPyutao </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EPyutao</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://EPyutao.com/2017/04/27/Tensorflow-4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EPyutao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatarpic.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EPyutao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/27/Tensorflow-4/" itemprop="url">
                  Tensorflow-4
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-27T18:36:03+08:00">
                2017-04-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>使用CNN完成一个验证码识别demo，详细代码见 <a href="https://github.com/EPyutao/tfProject/tree/master/Yanzhengma" target="_blank" rel="external">github</a> (使用版本Tensorflow 1.0)：  </p>
<h3 id="验证码生成"><a href="#验证码生成" class="headerlink" title="验证码生成"></a>验证码生成</h3><p>常规的使用python生成验证码方法是生成字母与数字的组合，将单个元素进行旋转，添加背景色，噪点，干扰线等。本文中使用ImageCaptcha来生成验证码。该package可以加载自己的字体图片库，并在生成的验证码上随机添加30个噪点并绘制噪声曲线。使用 pip 安装ImageCaptcha，编写一个生成随机验证码list的函数，并将其转换为str数据结构，调用ImageCaptcha.generate(str)生成验证码图片。调用PIL库中的Image.open() 和 numpy.array()将图片转换为np.ndarray数据结构。文件为gen_captcha.py</p>
<h3 id="模型与训练"><a href="#模型与训练" class="headerlink" title="模型与训练"></a>模型与训练</h3><p>构造工具函数，包含ImageCaptcha生成的验证码转换为灰度图，该图大小为[60,160,3]；将标签文本转换为向量；将向量转换为标签文本；生成训练batch，size=64，将灰度图转换为一维数据。模型部分采用CNN模型，使用3层卷积2层全连接，对输出层的数据计算和标签的sigmod_cross_entropy作为损失函数。<strong>当模型精度达到0.9时停止训练，此时训练步数为13400步，相当于训练集达到了857600张图片，而验证码生成的图片总共可以达到八百万张，因此只使用了其中十分之一的数据，就训练到了90%的准确率。</strong> 文件为train.py。保存模型后，同级目录下出现4个文件，checkpoint存储了model的位置，其余为二进制文件。而在恢复过程中，调用tf.train.latest_checkpoint函数则是直接检索该文件内内容，并返回给saver.restore的save_path。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>调用同一级目录下保存的训练模型，文件为test.py：</p>
<pre><code>
from train import *
from gen_captcha import gen_captcha_text_and_image


def crack_captcha(captcha_image):
    output = crack_captcha_cnn()

    saver = tf.train.Saver()
    with tf.Session() as sess:
        saver.restore(sess, tf.train.latest_checkpoint('.'))

        predict = tf.argmax(tf.reshape(output, [-1, MAX_CAPTCHA, CHAR_SET_LEN]), 2)
        text_list = sess.run(predict, feed_dict={X: [captcha_image], keep_prob: 1})

        text = text_list[0].tolist()
        vector = np.zeros(MAX_CAPTCHA * CHAR_SET_LEN)
        i = 0
        for n in text:
            vector[i * CHAR_SET_LEN + n] = 1
            i += 1
        return vec2text(vector)


text, image = gen_captcha_text_and_image()
print(image.shape)


image = convert2gray(image)
print(image.shape)
image = image.flatten() / 255
print(image.shape)

predict_text = crack_captcha(image)

print("正确: {}  预测: {}".format(text, predict_text))
</code></pre>
最终测试结果如下：
![right](http://epyutao.oss-cn-shanghai.aliyuncs.com/figure_2.png)
<pre><code>
正确: jkMf  预测: jkMf
</code></pre>
反复测试中，也发现了错误。
![wrong](http://epyutao.oss-cn-shanghai.aliyuncs.com/figure_1.png)
<pre><code>
正确: e8g2  预测: e8B2
</code></pre>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://EPyutao.com/2017/04/18/Tensorflow-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EPyutao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatarpic.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EPyutao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/18/Tensorflow-3/" itemprop="url">
                  Tensorflow_3
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-18T22:37:40+08:00">
                2017-04-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>图像检测深度学习方法经历了多代，前段时间 He kaiming 与 Ross 合作提出了 Mask-RCNN 模型，此文来整理一下 R-CNN,SPPnet Fast R-CNN, Faster R-CNN, Mask R-CNN 这一系列的深度学习图像检测模型和几个该领域传统的一些概念。  </p>
<h3 id="HOG特征"><a href="#HOG特征" class="headerlink" title="HOG特征"></a>HOG特征</h3><p>方向梯度直方图（Histogram of Oriented Gradient, HOG）特征是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。它通过计算和统计图像局部区域的梯度方向直方图来构成特征。实现方式大抵如下：1.对输入图像灰度处理并对颜色空间归一化处理 2.计算每个像素的梯度(大小和方向)即采用[-1,0,1]和[1,0,-1]的卷积核对图像做卷积 3.将图像划分为多个小cell，统计每个cell的梯度直方图(每个像素点的梯度方向x梯度值) 4.将多个cell合并为一个block，对block内做归一化处理。<br>当梯度方向采用九个方向离散时，则一个cell内的HOG特征维数为9。</p>
<h3 id="Bounding-Box"><a href="#Bounding-Box" class="headerlink" title="Bounding Box"></a>Bounding Box</h3><p>包围盒，用体积稍大而且特性简单的几何体来近似代替复杂的几何对象。selective search后的st使用bounding box来包围，可有效提高准确率，在R-CNN中，mAP达到了53.7。tensorflow在tf.image中有相关的函数。</p>
<h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><p>R-CNN 是 Ross Girshick 在 <em>Rich feature hierarchies for accurate object detection and semantic segmentation</em> 一文中提出的一种 object detection 结构。其在数据集 PASCAL VOC 上测试了效果。R-CNN的整体框架为：1.输入image 2.提取候选区域extract region proposals(约2k个) 3.warped region(‘regardless of the size, we warp all pixels in a tight bounding box’) 4.Compute CNN feature 5.Classify regions.  </p>
<ul>
<li>候选区选取采用 <em>Selective Search for Object Recognition</em> 一文中Uijlings等人的的 selective search 方法。该方法具有能捕捉多尺度目标，多元化和能够快速计算的特点。采用 Hierarchical Grouping 分层次分组来形成基本的候选区域，具体是使用 bottom-up grouping。首先是产生大量初始区域，然后计算相邻候选区域的相似度，获取相似度最高的两个区域进行合并，直到所有区域合并为一体。文中采用了4个概念来描述相似度，color similarity; texture similarity; size similarity(for encouraging small regions to merge early); fill similarity。 4种相似度乘以不同的加权系数的加和构成两相邻区域相似度评价标准。文中提到的另一个概念就是多样化策略 Diversification Strategies。针对不同的图像采用不同的策略来获得更好的结果。也可以在不同的颜色通道RGB/HSV中进行 slective search ，以防遗漏候选区域。以下是分层次分组算法的伪代码<pre><code>Hierarchical Grouping Algorithm<br>Input: (colour) image<br>Output: Set of object location hypotheses L<br>Obtain initial regions R = {r1,··· ,rn}<br>Initialise similarity set S = 0<br>foreach Neighbouring region pair (ri, rj) do<br>Calculate similarity s(ri, rj)<br>S = S ∪ s(ri, rj)<br>while S != 0 do<br>Get highest similarity s(ri, rj) = max(S)<br>Merge corresponding regions rt = ri ∪ rj<br>Remove similarities regarding ri : S = S \ s(ri, r∗)<br>Remove similarities regarding rj : S = S \ s(r∗, rj)<br>Calculate similarity set St between rt and its neighbours<br>S = S ∪ St<br>R = R ∪ rt<br>Extract object location boxes L from all regions in R</code></pre></li>
<li>将候选区域warp成归一化尺寸227x227。归一化的方法有直接各向异性缩放(即直接缩放)与各向同性缩放。</li>
<li>采用5层卷积和2层全连接的CNN网络进行训练，先采用alexnet的参数初始化该网络的参数，然后输入selective search 的候选区域进行fine-tuning微调。Alexnet最后一层全连接的输出通道为10，微调时改为N+1个，多出来一个为背景。有论文采用VGG-17的网络结构进行初始化。论文采用SGD随机梯度下降法，每个迭代步有32张包含10个类别的图片和96张背景图片构成。图片进入网络后，比较候选框与当前图像上所标定框重叠面积最大的一个，如果重叠比例大于0.5，则认为该候选框为标定的类别，否则认为该候选框为背景。</li>
<li>对每一类目标，采用一个线性脊回归器进行精修，输出为xy方向的缩放和平移，训练样本为该类候选框中，真值重叠面积大于0.6的候选区域。</li>
</ul>
<h3 id="SPPnet"><a href="#SPPnet" class="headerlink" title="SPPnet"></a>SPPnet</h3><p>由于R-CNN计算中对每个候选区域进行了卷积操作，造成了大量的冗余，He Kaiming 在 <em>Spatial pyramid pooling in deep convolutional networks for visual recognition</em> 一文中提出了SPPnet结构，优化了R-CNN。文中指出，卷积层并不需要固定输入图片的尺寸并且可以产生不同尺寸的特征图，而全连接层需要一个固定的输入。因此，作者提出了 spatial pyramid pooling 空间金字塔池化结构来解除对网络固定尺寸的限定。spp层加载在最后一层卷积层和全连接层之间。文中提出的spp层结构是采用三种大小的池化滑窗pooling windows(5x5,7x7,13x13)，产生三种大小的池化结构(3x3,2x2,1x1)，三种格子的结果concat后送入全连接层。<br>具体应用中，先将整图输入训练好的sppnet中，得到多层卷积输出，然后根据2000多个候选区域在卷积层中的映射位置，将这些候选区域送入SPP层获得一个相同的输出，将该输出送入全连接层进行分类。<br>过去的R-CNN中，由于候选区域采用crop或warp处理方式，使得识别准确率难以提高，而必须采用crop或warp的原因是，全连接层的输入是固定长度，所以在SPPnet中采用spp来使得全连接层的输入变为固定长度而提高准确率。</p>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><p>Ross Girshick大神在去微软后，提出了改进的R-CNN模型，发表在论文 <em>Fast R-CNN</em> 中。模型将目标检测的四个基本步骤：候选区域生成，特征提取，分类，位置修正，统一到了一个网络框架中，并且没有冗余。该模型修正了R-CNN与SPPnet的缺点，使用caffe开发并进行了开源。该模型首先初始化了一些预训练的网络，这些网络由5~13层卷积层与5层maxpooling层构成，并将最后一层maxpooling用RoI pooling层代替,将区域特征提取放在这一层。随后将最后一层全连接层和softmax层用两个同级层代替(一个产生k+1类softmax结果，另一个对特定类的bounding box 进行修正)。最后调整网络结构，使其能够接受两种输入list of image &amp; list of RoIs。<br>RoI pooling采用最大池化将一个候选区域的特征转换成一个具有固定大小的小特征图，可以看做是一个SPPnet的简化版本，每个RoI用包含有左上角坐标和长宽的tuple来表示。<br>loss function 由softmax分类结果和bounding box的定位结果构成。论文中详细给出了每种任务的loss function具体形式。</p>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p>Fast R-CNN的候选区域仍由selective search来生成，而在Fater R-CNN中则全部都用deep learning来实现了。Kaiming He 与 RBG 合作的论文 <em>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</em> 中提出了一种新的R-CNN结构，提出Region Proposal Network(RPN)来取代过去的selective search方法进行候选区域的提取。RPN中，采用了pyramid of regression references方案，避免了selective search采用枚举的来产生候选区域。网络结构在过去的Fast R-CNN中，在多层卷积后加入RPN结构，RPN连接卷积层输出的feature map，采用一个类似于RoI的结构，输出两个层，一个为该anchor为建议区域的概率，另一个则是boundingbox regression。在RPN中，通过一个anchor扫描feature map，而每个滑窗对应k个anchor boxes，使用这个方法来提高scale-invariant,具体实践时，对feature map上每个位置，考虑三种面积x三种比例的候选区域(anchor)，输出层中，classification层输出每个位置上，这9个anchor属于前景或者背景的概率，boundingbox regression层则输出每个位置上9个anchor对应的boundingbox的平移缩放参数。对于RPN的输入样本而言，将这么多anchor与标定的真值区域对比，将重叠比例最大的记为前景样本。对于剩下的anchor，如果与某个标定的anchor重叠大于0.7，也标记为前景样本，与任意标定的anchor重叠都小于0.3，则标记为背景样本。处于中间的丢弃不用。<br>采用Alternating training方式进行训练：1.训练RPN(第一次时采用ImageNet得到的数据来进行初始化)；2.用RPN获得的区域训练Fast R-CNN(第一次时，同样采用ImageNet来初始化);3.由于共享参数，将RPN中的卷积层参数再次初始化。反复迭代，知道训练结束。</p>
<h3 id="YOLO-darknet"><a href="#YOLO-darknet" class="headerlink" title="YOLO-darknet"></a>YOLO-darknet</h3><p><em>YOLO9000:Better, Faster, Stronger</em> Joseph Redmon &amp; Ali Farhadi<br>YOLO的anchor选取更粗暴，将图像划分为s*s个网络，对每个网络预测和训练5个参数(中心坐标，长宽，置信度评分)后面是常规的多层卷积和全连接。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://EPyutao.com/2017/04/08/Tensorflow-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EPyutao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatarpic.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EPyutao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/08/Tensorflow-2/" itemprop="url">
                  Tensorflow_2
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-04-08T20:34:57+08:00">
                2017-04-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>文中总结了几个经典的CNN模型和概念。模型实现代码详见<strong>Github</strong>。</p>
<h3 id="one-hot"><a href="#one-hot" class="headerlink" title="one-hot"></a>one-hot</h3><p>For the purposes of this tutorial, we’re going to want our labels as “one-hot vectors”. A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension.<br>拿到获取的原始特征，必须对每一特征分别进行归一化.  </p>
<ul>
<li>连续型特征归一化的常用方法: Rescale bounded continuous features 线性缩放 Standardize all continuous features 放缩到均值为0，方差为1  </li>
<li>离散型特征的处理方法  Binarize categorical/discrete features: For all categorical features, represent them as multiple boolean features. For example, instead of having one feature called marriage_status, have 3 boolean features - married_status_single, married_status_married, married_status_divorced and appropriately set these features to 1 or -1. As you can see, for every categorical feature, you are adding k binary feature where k is the number of values that the categorical feature takes.对于离散的特征基本就是按照one-hot编码，该离散特征有多少取值，就用多少维来表示该特征 比如对于0-9个数字 其中数字3就是[0,0,0,1,0,0,0,0,0,0,0]  </li>
</ul>
<h3 id="卷积核尺寸"><a href="#卷积核尺寸" class="headerlink" title="卷积核尺寸"></a>卷积核尺寸</h3><p>conv2d而言，输入的通道数目即为卷积核的高，输出通道数据为卷积核的数量。</p>
<h3 id="Xavier-initialization"><a href="#Xavier-initialization" class="headerlink" title="Xavier initialization"></a>Xavier initialization</h3><p>一种新的初始化权重的方式，输出值在很多层后依然保持良好的分布特性。<br>当处于ReLU网络时，为保持Variance不变，采用 He initialization</p>
<pre><code> W = tf.Variable(np.random.randn(node_in, node_out)) / np.sqrt(node_in)
  // He for ReLU
  W = tf.Variable(np.random.randn(node_in, node_out)) / np.sqrt(node_in/2)
</code></pre>

<h3 id="LRN局部响应归一化"><a href="#LRN局部响应归一化" class="headerlink" title="LRN局部响应归一化"></a>LRN局部响应归一化</h3><p>具体实现的代码为gen_nn_ops.py中的lrn函数。args=[input, depth_radius, bias, alpha, beta, name]。采用临近抑制的操作，对局部输入区域进行归一化计算。<pre><code> sqr_sum[a, b, c, d] =<br>      sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ^ 2)<br>    output = input / (bias + alpha * sqr_sum) ^ beta<br></code></pre></p>
<h3 id="L2正则"><a href="#L2正则" class="headerlink" title="L2正则"></a>L2正则</h3><p>w = tf.nn.multiply(tf.nn.l2_loss(random), random)<br>Computes half the L2 norm of a tensor without the sqrt: output = sum(t ** 2) / 2<br>采用tf.nn.l2_loss(tensor)对一个张量求l2正则，loss function最终则为entropy loss和l2_loss的和</p>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>Alex Krizhevsky是Hinton的学生，其在2012年的NIPS上的论文 <em>ImageNet Classification with Deep Convolutional Neural Networks</em> 提出的一个大型深度卷积神经网络AlexNet，将ImageNet LSVRC-2010比赛中的120万张高清图片分为了1000个不同的类别。测试集的错误率达到了15.3%<br>Alex的结构包含了8个学习层（5个卷积层和3个全连接层）。文章中称，减少任何一个卷积结果都会让结果变差。 其采用了一些新颖独特的方法来构造整个网络体系</p>
<ul>
<li>使用ReLU作为CNN的激活函数。ReLU是神经元Integrate&amp;Fire模型的一个近似，数学表达形式为 <em>f(x) = max(0,x)</em> 该激活函数在较深的网络中超过了Sigmoid,成功解决了网络较深时的梯度弥散问题。</li>
<li>训练时采用Dropout随机忽略一些神经元，避免造成过拟合。Alex在论文中，以0.5的概率将每个隐藏神经元的输出设置为零。而这种dropout的神经元即不利于前向传播，也不参与反向传播，所以每一次输入，神经网络就会尝试一种不同的结构。这种手段降低了神经元复杂的互适应关系。Alex对两个全连接层都使用了dropout，防止过拟合，但收敛的次数增加了一倍。</li>
<li>在CNN中使用重叠的最大池化。Alex提出让步长比池化核的尺寸小，这样池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。  </li>
<li>采用局部响应化归一（Local Response Normalization）。因为ReLU的值域不像其他激活函数有一个闭区间，所以要做一个Normalization,所以采用LRN来处理。LRN层模仿了生物神经系统的”侧抑制”机制,对局部神经元的活动创建竞争环境,使得其中响应比较大的值变得相对更大,并抑制其他反馈较小的神经元,增强了模型的泛化能力。需要注意的是LRN对Relu这种没有上限边界的激活函数会比较有用,因为它会从附近的多个卷积核的响应中挑选比较大的反馈,但不适合sigmoid这种有固定边界并且能抑制过大的激活函数。  </li>
<li>数据增强。随机从256x256的原始图像中截取224x224大小的区域（或水平翻转），来增加数据集，但该方法产生的数据集会高度地相互依赖。还有一种方法是改变RGB通道的强度，Alex在整个训练集的RGB像素上执行PCA分析，对于每个训练图，成倍增加主成分，比例大小为对应特征乘以一个均值为0，标准差为0.1的高斯分布。</li>
</ul>
<h3 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h3><p>paper详见 <em>Going deeper with convolutions</em> 。GoogleNet是ILSVRC2014的冠军，该模型借鉴了Network-in-Network的思想，大大增加了CNN的深度，提出了一个超过20层的CNN结构，在GoogleNet中，主要采用3中类型的卷积操作（1x1， 3x3， 5x5），组合后接入下一层。基础的Network-in-Network在卷积层采用了MLPconv，在每个local部分进行了比传统卷积层复杂的计算，提高每一层卷积层对复杂特征的识别能力。采用全局均值池化来解决传统CNN网络中最后全连接层参数过于复杂的特点，而全连接层会造成网络的泛化能力变差，因此使用dropout来提高网络的泛化能力。GoogLeNet采用了Inception module，采用不同尺寸的卷积核来处理前一层过来的tensor，同时提出了’Inception module with dimension reduction’，在3x3和5x5卷积核之前使用1x1的卷积核先进性降维，可以在不损失模型特征表示能力下，尽量减少filters的数量，而减少Model复杂度。文章中给了详细的网络层布置：卷积-&gt;池化-&gt;卷积-&gt;池化-&gt;Inception-&gt;池化-&gt;Inception-&gt;池化-&gt;Inception-&gt;池化-&gt;dropout-&gt;linear-&gt;softmax<br>。在Inception层中，采用不同尺寸的卷积核产生conv2d，同一层的不同con2vd和maxpooling层采用merge产生该inception层的输出.借鉴tflearn，merge的一般形式可以为</p>
<p><pre><code>def merge(tensor1, tensor2, tensor3, axis)<br>  // aixs: int. Represent the axis to use for merging mode.<br>  // 此处axis为3，代表合并后长宽不变，高度上相加。即depth concat<br>  return tf.concat([tensor1, tensor2, tensor3], axis)<br></code></pre><br>高度相加后，就是随后的layer的输入。注意论文中给出的表格所谓#5<em>5reduce代表在该5x5卷积之前使用了1x1的卷积核先进行了降维。pool层的卷积核数目是指将输入尺寸采用stride为1进行池化，再以表格中给予的卷积核数目进行1</em>1卷积降维。</p>
<h3 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h3><p>Simonyan等人在 <em>Very deep convolutional networks for larger-scale image recognition</em> 中提出了VGG模型，即采用在现有的网络中不断增加具有3*3卷积核的卷积层来增加网络的深度。通过实验发现，当权值层数达到16-19层时，模型的性能能得到有效的提升。VGG模型用具有小卷积核的多个卷积层替换一个具有较大卷积核的卷积层（如用大小均为3x3的卷积核的三层卷积层替换一层具有7x7卷积核的卷积层），这种替换减少了参量的数量，也是的决策函数更具有判别性。VGG模型在LSVRC-14竞赛中取得很好的成绩。VGGnet中也引入了1x1卷积核，不过此处卷积核数目和输入数据通道个数一致，所以不会对数据进行降维。其目的是:’a way to increase the non-linearity of the decision function without affecting the receptive fields of the conv. layers’.</p>
<h3 id="ResNet-残差网络"><a href="#ResNet-残差网络" class="headerlink" title="ResNet 残差网络"></a>ResNet 残差网络</h3><p>ResNet是 He Kaiming 等人在 <em>Deep Residual Learning for Image Recognition</em> 一文中提出的模型。在传统深层的神经网络模型中，除了存在梯度扩散的问题外，还存在梯度退化问题：即随着深度增加，网络精度达到饱和，然后迅速下降。残差网络（Residual Nerworks）可以有效的解决退化问题。ResNet主要特点是跨层连接，通过引入捷径连接技术（shorcut connections）将输入跨层传递并与卷积的结果相加。在ResNet中只有一个取样层，其连接在卷积层的最后面。ResNet通过捷径连接技术使得输入通过多个路径流入最顶层，大幅降低了更深层模型的训练难度。该方法与VGGnet结合使用，具有很好的效果。作者提出一种结构来做residual learning.将一部分的输入信息，直接跳过layers，将其与通过layers的输出进行比较，整个网络则学习这个差别。在tflearn中构造了这个单元</p>
<p><pre><code><br>def residual_block():<br>  Arguments:<br>      incoming: <code>Tensor</code>. Incoming 4-D Layer.<br>      // layer blocks为多层卷积核大小一致，输出通道数一致的卷积层。<br>      nb_blocks: <code>int</code>. Number of layer blocks.<br>      out_channels: <code>int</code>. The number of convolutional filters of the<br>          convolution layers.<br>      downsample: <code>bool</code>. If True, apply downsampling using<br>          ‘downsample_strides’ for strides.<br>      downsample_strides: <code>int</code>. The strides to use when downsampling.<br>      activation: <code>str</code> (name) or <code>function</code> (returning a <code>Tensor</code>).<br>          Activation applied to this layer (see tflearn.activations).<br>          Default: ‘linear’.<br>      batch_norm: <code>bool</code>. If True, apply batch normalization.<br>      bias: <code>bool</code>. If True, a bias is used.<br>      weights_init: <code>str</code> (name) or <code>Tensor</code>. Weights initialization.<br>          (see tflearn.initializations) Default: ‘uniform_scaling’.<br>      bias_init: <code>str</code> (name) or <code>tf.Tensor</code>. Bias initialization.<br>          (see tflearn.initializations) Default: ‘zeros’.<br>      regularizer: <code>str</code> (name) or <code>Tensor</code>. Add a regularizer to this<br>          layer weights (see tflearn.regularizers). Default: None.<br>      weight_decay: <code>float</code>. Regularizer decay parameter. Default: 0.001.<br>      trainable: <code>bool</code>. If True, weights will be trainable.<br>      restore: <code>bool</code>. If True, this layer weights will be restored when<br>          loading a model.<br>      reuse: <code>bool</code>. If True and ‘scope’ is provided, this layer variables<br>          will be reused (shared).<br>      scope: <code>str</code>. Define this layer scope (optional). A scope can be<br>          used to share variables between layers. Note that scope will<br>          override name.<br>      name: A name for this layer (optional). Default: ‘ShallowBottleneck’.<br>      // 每个block layers包含两个3*3的卷积层，<br>        tmp = incoming<br>        resnet = conv2d(incoming)<br>        resnet = conv2d(resnet)<br>        return resnet + tmp<br></code></pre><br>tflearn中的residual_block的实现实际上是对He在论文中提到的适用于resnet-34的block，他还提到一种1x1-&gt;3x3-&gt;1x1三层结构的bottleneck结构，这种结构适用于ResNet-50/101/152的深度。其余部分与传统的CNN训练方式一致。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://EPyutao.com/2017/02/18/Tensorflow-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="EPyutao">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatarpic.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EPyutao">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/18/Tensorflow-1/" itemprop="url">
                  Tensorflow_1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-02-18T15:46:48+08:00">
                2017-02-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>去年11月底，Google宣布了Tensorflow对win10的支持，我便尝试在gtx1060的笔记本上试水tensorflow-gpu计算，进行machine learning的入门学习。</p>
<h3 id="Tensorflow-GPU版本安装"><a href="#Tensorflow-GPU版本安装" class="headerlink" title="Tensorflow GPU版本安装"></a>Tensorflow GPU版本安装</h3><p>win10下安装tensorflow-gpu版本有要求先安装以下前置环境：</p>
<ul>
<li>DXSDK_Jun10.exe 微软的DirectX SDK工具包 安装完成后’d3dx9/10/11.h’三个头文件存在即可</li>
<li>Cuda Nvidia发行的GPGPU程序  安装完成后能将CUDA_Samples实例编译通过不报错即可</li>
<li>cuDNN Nvidia发行的GPU加速补丁，下载完成后将压缩包内文件替换掉’path:\NVIDIA GPU Computing Toolkit\CUDA\v8.x’即可</li>
</ul>
<p>当前置环境配置好后，就可以安装Tensorflow -GPU了，推荐使用Anaconda发行版来安装tensorflow。这里有一些坑需要注意，2017-2-4时，tf-windows版仅支持 python 3.5.x。而此时Anaconda官网默认下载版本是Anaconda 4.3.0.1，对应的python默认版本是python 3.6，所以如果安装过去一些教程提到的使用’pip install tensorflow-gpu’则会报错。因此tf官网推荐采用conda管理工具来为tensorflow配置所需的python库和python版本list，在此环境下pip安装tensorflow</p>
<pre><code>C:> conda create -n tensorflow
C:> activate tensorflow
(tensorflow)C:> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl
</code></pre>

<h3 id="Tensorflow基本计算模式"><a href="#Tensorflow基本计算模式" class="headerlink" title="Tensorflow基本计算模式"></a>Tensorflow基本计算模式</h3><p>Tensorflow采用Session来启动一个artificial neural network，而neural network在tf里以图graph的形式来表示。对于ml工程类而言，其任务根据论文构造出的neural network采用tf实现出来，并通过调参来获得其在工业界不同细分领域的应用。<br>构建好graph后，将所有具有tf数据结构的参量进行<strong>inital</strong>后，就可以采用Session()来启动训练。</p>
<p><pre><code>import tensorflow as tf<br>tf.Session().run(tf.train.OptimizerMethod(learning rate).minimize(loss_function()))</code></pre><br>run方法是训练的入口，其训练的是采用某种OptimizerMethod来计算loss_function()。<br>其中最常见训练方法的就是梯度下降算法GradientDescentOptimizer，但梯度下降算法有着局部最优，过拟合，梯度弥散等缺点。2006年Hinton等人提出了新的训练方法OptimizerMethod，才使得深层神经网络的应用成为现实。tf封装了大量的优化算法，使得工程类的应用可以不用花太多时间在各个训练方法的实现细节。</p>
<h3 id="CNN的实现"><a href="#CNN的实现" class="headerlink" title="CNN的实现"></a>CNN的实现</h3><p>卷积神经网络CNN在图像识别领域有着极强的应用，Kaggle上’Dogs vs Cats’, ‘Fisheries Monitoring’等问题的most votes kernel很多都采用CNN的内核去实现。<br>CNN由两部分组成，Convolution卷积 和 Full connection全连接神经网络层。<br>一个基本的卷积层完成两件事，convolution和subsampling。convolution是一个采样过程，在tf中，通过设置stride和padding来拉升图片在’高度’方向上的长度,当stride=1时，图片处理后长宽不变。subsampling是采用pooling方法将图片在’长’和’宽’方向压缩。二者作用图片后，将图片变窄变高。</p>
<p><pre><code>def weight_variable(shape):<br>    inital = tf.trunacted_normal(shape, stddev=0.1)<br>    return tf.Variable(inital)<br>def bias_variable(shape):<br>    initial = tf.constant(0.1, shape=shape)<br>    return tf.Variable(initial)</code></pre><br>先为不同的Neural network层定义weights和bias</p>
<p><pre><code>def conv2d(x, W):<br>    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=’SAME’)<br>def max_pool_2x2(x):<br>    return tf.nn.max_pool(x, ksize=[1,2,2,1],strides=[1,2,2,1], padding=’SAME’)</code></pre><br>随后编写convolution和subsampling层。</p>
<p><pre><code><br>FullFunc2 = tf.nn.relu(tf.matmul(tf.nn.dropout(FullFunc2), W_FF2) + b_FF2)<br></code></pre><br>这是全连接层的基本形式，将上一个隐藏层的数据采用dropout方法修建，在进行矩阵计算matmul，最后采用relu进行节点的激活。<br>CNN图Graph的构建形式大致如此。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  

          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatarpic.jpg"
               alt="EPyutao" />
          <p class="site-author-name" itemprop="name">EPyutao</p>
           
              <p class="site-description motion-element" itemprop="description">念念不忘 必有回响</p>
          
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/EPyutao" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">EPyutao</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  

  

  

  


  

</body>
</html>
